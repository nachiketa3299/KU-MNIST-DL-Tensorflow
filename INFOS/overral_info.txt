preset	batch_size	activation_function	#_of_layers	layer_size	training_epoch	weight_init	optimizer	weight_decay	dropout	training_time	early_stopping	val_maxAcc	timestamp
1	200	relu	3	(300, 200)	30	None	adam	0.001	0	0	0.7752837856610616	27	0.9855999946594238	1600582437
2	200	relu	4	(200, 200, 200)	100	None	adam	0.001	0	0	2.247453423341115	99	0.984000027179718	1600582485
3	200	relu	4	(600, 600, 800)	100	None	adam	0.001	0	0	8.19914806286494	92	0.9869999885559082	1600582621
4	200	relu	4	(200, 200, 200)	100	None	adam	0.001	0	0	2.2561684966087343	58	0.9864000082015991	1600583115
5	200	relu	4	(200, 200, 200)	100	he	adadelta	0.001	0	0	3.093410646915436	100	0.8399999737739563	1600583252
6	200	relu	4	(200, 200, 200)	100	he	adam	0.001	0.01	0	2.264973004659017	95	0.9319999814033508	1600583439
7	200	relu	4	(200, 200, 200)	100	he	adam	0.01	0.01	0	2.2403691093126934	63	0.9093999862670898	1600583576
8	200	relu	4	(200, 200, 200)	100	he	adam	0.01	0.01	0.2	2.8547411799430846	9	0.8583999872207642	1600583713
9	100	relu	3	(300, 200)	100	None	adam	0.001	0	0	3.06465247074763	77	0.9861999750137329	1600583886
10	100	relu	4	(300, 200, 200)	100	None	adam	0.001	0	0	3.580374590555827	74	0.9864000082015991	1600584071
11	100	relu	5	(300, 200, 200, 200)	100	None	adam	0.001	0	0	4.142751495043437	46	0.9855999946594238	1600584287
12	100	relu	6	(300, 200, 200, 200, 200)	100	None	adam	0.001	0	0	4.79114781220754	100	0.9855999946594238	1600584538
13	100	relu	7	(300, 200, 200, 200, 200, 200)	100	None	adam	0.001	0	0	5.491605850060781	62	0.9854000210762024	1600584828
14	100	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0	0	4.18297723531723	60	0.9850000143051147	1600585160
15	100	relu	5	(300, 200, 200, 200)	100	xe	adam	0.001	0	0	4.14860280752182	65	0.9855999946594238	1600585412
16	100	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.1	0	4.450520924727122	3	0.11259999871253967	1600585663
17	100	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.01	0	4.242407687505087	58	0.9229999780654907	1600585932
18	100	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.001	0	4.181627333164215	88	0.9779999852180481	1600586188
19	100	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.001	0.2	4.82210525671641	62	0.9649999737739563	1600586441
20	100	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.001	0.5	4.9083413998285925	78	0.9435999989509583	1600586733
21	100	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.001	0.8	5.136655529340108	92	0.8068000078201294	1600587030
22	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.001	0.2	3.828347587585449	43	0.9670000076293945	1600587340
23	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.001	0.15	3.5772575616836546	94	0.9711999893188477	1600587572
24	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.001	0.25	3.7084038416544596	57	0.9642000198364258	1600587789
25	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.001	0.3	3.7074869672457376	96	0.9638000130653381	1600588014
26	200	relu	5	(300, 200, 200, 200)	100	he	adadelta	0.001	0.001	0.2	4.314307300249736	100	0.3799999952316284	1600588239
27	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.01	0.2	3.786121388276418	88	0.902999997138977	1600588500
28	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.1	0.2	3.671378827095032	67	0.11559999734163284	1600588730
29	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	1	0.2	3.5419662952423097	5	0.11559999734163284	1600588952
30	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	10	0.2	3.52989688316981	8	0.11599999666213989	1600589167
31	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.001	0.0001	0.2	3.659075967470805	87	0.9797999858856201	1600589382
32	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.01	0.0001	0.2	3.5482006629308063	45	0.9467999935150146	1600589603
33	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.1	0.0001	0.2	3.4754175662994387	4	0.11259999871253967	1600589819
34	200	relu	5	(300, 200, 200, 200)	100	he	adam	1	0.0001	0.2	3.515910029411316	14	0.11259999871253967	1600590029
35	200	relu	5	(300, 200, 200, 200)	100	he	adam	0.0001	0.0001	0.2	3.8374825954437255	97	0.9771999716758728	1600590243
36	200	relu	4	(300, 200, 200)	100	he	adam	0.001	0.0001	0.2	3.081645369529724	98	0.9814000129699707	1600590475
37	200	relu	4	(300, 200, 200)	100	he	adam	0.001	0.01	0.2	3.214375332991282	90	0.9110000133514404	1600590662
